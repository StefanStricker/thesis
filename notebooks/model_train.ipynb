{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e177d1f1",
      "metadata": {},
      "source": [
        "# Model Training Notebook\n",
        "\n",
        "This notebook trains the three CNN Architectures (ResNet, DenseNet, ConvNeXt), each under 4 different augmentation strategies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "22d20b92",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d0ba08e5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.9.0+cu128'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b7612515",
      "metadata": {},
      "outputs": [],
      "source": [
        "#data_paths\n",
        " \n",
        "input_path = Path(\"../data/datasets/trashnet\")\n",
        "input_path2 = Path(\"../data/datasets/trashvariety\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "75ab7f85",
      "metadata": {},
      "outputs": [],
      "source": [
        "#function to save models later on\n",
        "\n",
        "model_dir = \"../trained_models\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "def save_model(model, model_name, history=None):\n",
        "    save_path = os.path.join(model_dir, f\"{model_name}.pth\")\n",
        "\n",
        "    checkpoint = {\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "    }\n",
        "\n",
        "    if history is not None:\n",
        "        checkpoint[\"history\"] = history\n",
        "\n",
        "    torch.save(checkpoint, save_path)\n",
        "    print(f\"Model saved\")    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e1d693c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 64\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e4dbb0bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6821f7d6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
            "Train counts: Counter({3: 475, 1: 400, 4: 385, 2: 328, 0: 322, 5: 109})\n",
            "Class weights: tensor([0.8270, 0.6657, 0.8119, 0.5606, 0.6917, 2.4431], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "#calculate class weighted cross entropy loss\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def compute_class_weights_from_imagefolder(train_root, num_classes):\n",
        "    ds = datasets.ImageFolder(train_root, transform=transforms.ToTensor())\n",
        "    counts = Counter(ds.targets)\n",
        "    total = sum(counts.values())\n",
        "\n",
        "    weights = [total / counts[i] for i in range(num_classes)]\n",
        "    weights = torch.tensor(weights, dtype=torch.float)\n",
        "    weights = weights / weights.sum() * num_classes \n",
        "    return weights, ds.classes, counts\n",
        "\n",
        "tmp_ds = datasets.ImageFolder(input_path / \"train\")\n",
        "num_classes = len(tmp_ds.classes)\n",
        "\n",
        "class_weights, class_names, train_counts = compute_class_weights_from_imagefolder(\n",
        "    input_path / \"train\",\n",
        "    num_classes\n",
        ")\n",
        "\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "criterion_weighted = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Train counts:\", train_counts)\n",
        "print(\"Class weights:\", class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "853de091",
      "metadata": {},
      "source": [
        "## Data Augmentation data transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "55b330fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# baseline data transforms\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "data_transforms = {\n",
        "\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),  \n",
        "        transforms.RandomHorizontalFlip(), \n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    \"val\": transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),    \n",
        "}\n",
        "\n",
        "image_datasets = {\n",
        "    \"train\": datasets.ImageFolder(input_path / \"train\", data_transforms[\"train\"]),\n",
        "    \"val\": datasets.ImageFolder(input_path / \"val\", data_transforms[\"val\"]),\n",
        "    \"test\": datasets.ImageFolder(input_path / \"test\", data_transforms[\"val\"]),\n",
        "}\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    \"train\": torch.utils.data.DataLoader(image_datasets[\"train\"], batch_size=32, shuffle=True, num_workers=4),\n",
        "    \"val\": torch.utils.data.DataLoader(image_datasets[\"val\"], batch_size=32, shuffle=False, num_workers=4),\n",
        "    \"test\": torch.utils.data.DataLoader(image_datasets[\"test\"], batch_size=32, shuffle=False, num_workers=4),\n",
        "}   \n",
        "\n",
        "\n",
        "dataset_size = {\n",
        "    \"train\": len(image_datasets[\"train\"]),\n",
        "    \"val\": len(image_datasets[\"val\"]),\n",
        "}\n",
        "\n",
        "num_classes = len((image_datasets[\"train\"]).classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "50c0f428",
      "metadata": {},
      "outputs": [],
      "source": [
        "#geometric augmentation\n",
        "\n",
        "data_transforms_geo = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.9, 1.1), shear=5),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    \"val\": transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]), \n",
        "}\n",
        "\n",
        "image_datasets_geo = {\n",
        "    \"train\": datasets.ImageFolder(input_path / \"train\", data_transforms_geo[\"train\"]),\n",
        "    \"val\": datasets.ImageFolder(input_path / \"val\", data_transforms_geo[\"val\"]),\n",
        "    \"test\": datasets.ImageFolder(input_path / \"test\", data_transforms_geo[\"val\"]),\n",
        "}\n",
        "\n",
        "dataloaders_geo = {\n",
        "    \"train\": torch.utils.data.DataLoader(image_datasets_geo[\"train\"], batch_size=32, shuffle=True, num_workers=4),\n",
        "    \"val\": torch.utils.data.DataLoader(image_datasets_geo[\"val\"], batch_size=32, shuffle=False, num_workers=4),\n",
        "    \"test\": torch.utils.data.DataLoader(image_datasets_geo[\"test\"], batch_size=32, shuffle=False, num_workers=4),\n",
        "}\n",
        "\n",
        "dataset_size_geo = {\n",
        "    \"train\": len(image_datasets_geo[\"train\"]),\n",
        "    \"val\": len(image_datasets_geo[\"val\"]),\n",
        "    \"test\": len(image_datasets_geo[\"test\"]),\n",
        "}\n",
        "\n",
        "num_classes_geo = len(image_datasets_geo[\"train\"].classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c86eda2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#photometric\n",
        " \n",
        "data_transforms_photo = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.1),\n",
        "        transforms.RandomGrayscale(p=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    \"val\": transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]), \n",
        "}\n",
        "\n",
        "image_datasets_photo = {\n",
        "    \"train\": datasets.ImageFolder(input_path / \"train\", data_transforms_photo[\"train\"]),\n",
        "    \"val\": datasets.ImageFolder(input_path / \"val\", data_transforms_photo[\"val\"]),\n",
        "    \"test\": datasets.ImageFolder(input_path / \"test\", data_transforms_photo[\"val\"]),\n",
        "}\n",
        "\n",
        "dataloaders_photo = {\n",
        "    \"train\": torch.utils.data.DataLoader(image_datasets_photo[\"train\"], batch_size=32, shuffle=True, num_workers=4),\n",
        "    \"val\": torch.utils.data.DataLoader(image_datasets_photo[\"val\"], batch_size=32, shuffle=False, num_workers=4),\n",
        "    \"test\": torch.utils.data.DataLoader(image_datasets_photo[\"test\"], batch_size=32, shuffle=False, num_workers=4),\n",
        "}\n",
        "\n",
        "dataset_size_photo = {\n",
        "    \"train\": len(image_datasets_photo[\"train\"]),\n",
        "    \"val\": len(image_datasets_photo[\"val\"]),\n",
        "    \"test\": len(image_datasets_photo[\"test\"]),\n",
        "}\n",
        "\n",
        "num_classes_photo = len(image_datasets_photo[\"train\"].classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d1a6de36",
      "metadata": {},
      "outputs": [],
      "source": [
        "#aug mix\n",
        " \n",
        "data_transforms_mix = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.9, 1.1), shear=5),\n",
        "        transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.1),\n",
        "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "        transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3), value='random')\n",
        "    ]),\n",
        "    \"val\": transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]), \n",
        "}\n",
        "\n",
        "image_datasets_mix = {\n",
        "    \"train\": datasets.ImageFolder(input_path / \"train\", data_transforms_mix[\"train\"]),\n",
        "    \"val\": datasets.ImageFolder(input_path / \"val\", data_transforms_mix[\"val\"]),\n",
        "    \"test\": datasets.ImageFolder(input_path / \"test\", data_transforms_mix[\"val\"]),\n",
        "}\n",
        "\n",
        "dataloaders_mix = {\n",
        "    \"train\": torch.utils.data.DataLoader(image_datasets_mix[\"train\"], batch_size=32, shuffle=True, num_workers=4),\n",
        "    \"val\": torch.utils.data.DataLoader(image_datasets_mix[\"val\"], batch_size=32, shuffle=False, num_workers=4),\n",
        "    \"test\": torch.utils.data.DataLoader(image_datasets_mix[\"test\"], batch_size=32, shuffle=False, num_workers=4),\n",
        "}\n",
        "\n",
        "dataset_size_mix = {\n",
        "    \"train\": len(image_datasets_mix[\"train\"]),\n",
        "    \"val\": len(image_datasets_mix[\"val\"]),\n",
        "    \"test\": len(image_datasets_mix[\"test\"]),\n",
        "}\n",
        "\n",
        "num_classes_mix = len(image_datasets_mix[\"train\"].classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edb01453",
      "metadata": {},
      "source": [
        "## Model Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b14f42c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, dataset_size, device,\n",
        "                criterion, optimizer, num_epochs=25):\n",
        "\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    history = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc\": [],\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(\"-\" * 10)\n",
        "\n",
        "        for phase in [\"train\", \"val\"]:\n",
        "            if phase == \"train\":\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0.0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == \"train\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_size[phase]\n",
        "            epoch_acc = running_corrects / dataset_size[phase]\n",
        "\n",
        "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "            if phase == \"train\":\n",
        "                history[\"train_loss\"].append(epoch_loss)\n",
        "                history[\"train_acc\"].append(epoch_acc)\n",
        "            else:\n",
        "                history[\"val_loss\"].append(epoch_loss)\n",
        "                history[\"val_acc\"].append(epoch_acc)\n",
        "\n",
        "            if phase == \"val\" and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
        "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff318a20",
      "metadata": {},
      "source": [
        "## Multi-run training (5 seeds)\n",
        "\n",
        "Run each architecture (ResNet50, DenseNet121, ConvNeXt-tiny) under each augmentation strategy (baseline, photo, geo, mixed) for 5 different seeds. Save each trained model with the seed in the filename and collect best validation accuracies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3dbaaf4",
      "metadata": {},
      "outputs": [],
      "source": [
        "seeds = [64, 128, 256, 512, 1024]\n",
        "archs = ['resnet50', 'densenet121', 'convnext_tiny']\n",
        "augs = {\n",
        "    'baseline': (dataloaders, dataset_size),\n",
        "    'photo': (dataloaders_photo, dataset_size_photo),\n",
        "    'geo': (dataloaders_geo, dataset_size_geo),\n",
        "    'mixed': (dataloaders_mix, dataset_size_mix),\n",
        "}\n",
        "\n",
        "results = {arch: {k: [] for k in augs.keys()} for arch in archs}\n",
        "\n",
        "for seed in seeds:\n",
        "    print(f\"\\n--- Starting run with seed {seed} ---\")\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    for aug_name, (dl, ds) in augs.items():\n",
        "        for arch in archs:\n",
        "            print(f\"Training {arch} with {aug_name} augmentations (seed {seed})\")\n",
        "\n",
        "            if arch == 'resnet50':\n",
        "                model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "                model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "            elif arch == 'densenet121':\n",
        "                model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
        "                model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
        "            elif arch == 'convnext_tiny':\n",
        "                model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.DEFAULT)\n",
        "                in_features = model.classifier[2].in_features\n",
        "                model.classifier[2] = nn.Linear(in_features, num_classes)\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown architecture: {arch}\")\n",
        "\n",
        "            model = model.to(device)\n",
        "            optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "            model, history = train_model(\n",
        "                model=model,\n",
        "                dataloaders=dl,\n",
        "                dataset_size=ds,\n",
        "                device=device,\n",
        "                criterion=criterion_weighted,\n",
        "                optimizer=optimizer,\n",
        "                num_epochs=25\n",
        "            )\n",
        "\n",
        "            save_model(model, f\"{arch}_{aug_name}_seed{seed}\", history)\n",
        "\n",
        "            best_val = max(history.get('val_acc', [])) if history.get('val_acc') else None\n",
        "            results[arch][aug_name].append(best_val)\n",
        "\n",
        "            del model\n",
        "            del optimizer\n",
        "            torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
